{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Chapter05.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3.8.5 64-bit ('anaconda3': virtualenv)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"interpreter":{"hash":"be4b63defce17d5a080b8f465a6563e41eb7f57f474d17922a3f2b4d2ad27abe"}},"cells":[{"cell_type":"markdown","metadata":{"id":"QB3WEyIVstl0"},"source":["# 5章\n","- 以下で実行するコードには確率的な処理が含まれていることがあり、コードの出力結果と本書に記載されている出力例が異なることがあります。"]},{"cell_type":"code","metadata":{"id":"kvqSUAEtU_VJ"},"source":["# ライブラリインポート\n","!pip install transformers==4.5.0 fugashi==1.1.0 ipadic==1.0.0"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers==4.5.0 in /Users/harukikondo/opt/anaconda3/lib/python3.8/site-packages (4.5.0)\n","Requirement already satisfied: fugashi==1.1.0 in /Users/harukikondo/opt/anaconda3/lib/python3.8/site-packages (1.1.0)\n","Requirement already satisfied: ipadic==1.0.0 in /Users/harukikondo/opt/anaconda3/lib/python3.8/site-packages (1.0.0)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /Users/harukikondo/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (0.10.3)\n","Requirement already satisfied: requests in /Users/harukikondo/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (2.24.0)\n","Requirement already satisfied: regex!=2019.12.17 in /Users/harukikondo/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (2020.10.15)\n","Requirement already satisfied: packaging in /Users/harukikondo/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (20.4)\n","Requirement already satisfied: filelock in /Users/harukikondo/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (3.0.12)\n","Requirement already satisfied: numpy>=1.17 in /Users/harukikondo/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (1.19.2)\n","Requirement already satisfied: sacremoses in /Users/harukikondo/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (0.0.45)\n","Requirement already satisfied: tqdm>=4.27 in /Users/harukikondo/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (4.50.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /Users/harukikondo/opt/anaconda3/lib/python3.8/site-packages (from packaging->transformers==4.5.0) (2.4.7)\n","Requirement already satisfied: six in /Users/harukikondo/opt/anaconda3/lib/python3.8/site-packages (from packaging->transformers==4.5.0) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /Users/harukikondo/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.5.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/harukikondo/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.5.0) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /Users/harukikondo/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.5.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/harukikondo/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.5.0) (2020.6.20)\n","Requirement already satisfied: joblib in /Users/harukikondo/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers==4.5.0) (0.17.0)\n","Requirement already satisfied: click in /Users/harukikondo/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers==4.5.0) (7.1.2)\n","\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n","You should consider upgrading via the '/Users/harukikondo/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"DWT32lOgHLrU"},"source":["# ライブラリのインポート\n","import numpy as np\n","import torch\n","from transformers import BertJapaneseTokenizer, BertForMaskedLM"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"I7X-Iy52AC1v"},"source":["# モデルの指定\n","model_name = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n","# トークナイザを用意する。\n","tokenizer = BertJapaneseTokenizer.from_pretrained(model_name)\n","bert_mlm = BertForMaskedLM.from_pretrained(model_name)\n","bert_mlm = bert_mlm.cuda()"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"error","ename":"AssertionError","evalue":"Torch not compiled with CUDA enabled","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-e3ec7961afc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertJapaneseTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbert_mlm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertForMaskedLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mbert_mlm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             raise AssertionError(\n","\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"]}]},{"cell_type":"code","metadata":{"id":"EfKt-j0WLOfx"},"source":["# 文章をトークン化して出力する。\n","text = '今日は[MASK]へ行く。'\n","tokens = tokenizer.tokenize(text)\n","print(tokens)"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["['今日', 'は', '[MASK]', 'へ', '行く', '。']\n"]}]},{"cell_type":"code","metadata":{"id":"YaW5Y9fM5zeM"},"source":["# 文章を符号化する。\n","input_ids = tokenizer.encode(text, return_tensors='pt')\n","# GPUに配置する。\n","input_ids = input_ids.cuda()\n","\n","# BERTに入力し、分類スコアを得る。\n","# 系列長を揃える必要がないので、単にiput_idsのみを入力します。\n","with torch.no_grad():\n","    output = bert_mlm(input_ids=input_ids)\n","    scores = output.logits"],"execution_count":5,"outputs":[{"output_type":"error","ename":"AssertionError","evalue":"Torch not compiled with CUDA enabled","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-9c86229f58e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# GPUに配置する。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# BERTに入力し、分類スコアを得る。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             raise AssertionError(\n","\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"]}]},{"cell_type":"code","metadata":{"id":"Z-5lnX9r8XKl"},"source":["# ID列で'[MASK]'(IDは4)の位置を調べる\n","mask_position = input_ids[0].tolist().index(4) \n","\n","# スコアが最も良いトークンのIDを取り出し、トークンに変換する。\n","id_best = scores[0, mask_position].argmax(-1).item()\n","# IDからトークンを取り出す。\n","token_best = tokenizer.convert_ids_to_tokens(id_best)\n","# ##を空欄に変換する。\n","token_best = token_best.replace('##', '')\n","# [MASK]を上で求めたトークンで置き換える。\n","text = text.replace('[MASK]',token_best)\n","# 出力する。\n","print(text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TgbIA-1-EVaJ"},"source":["# スコア上位10位のトークンを代入した際に文章を出力する関数\n","# text 対象文章\n","# tokenizer トークナイザー\n","# bert_mlm BERTモデル\n","# num_took 何位まで扱うかの数\n","def predict_mask_topk(text, tokenizer, bert_mlm, num_topk):\n","    \"\"\"\n","    文章中の最初の[MASK]をスコアの上位のトークンに置き換える。\n","    上位何位まで使うかは、num_topkで指定。\n","    出力は穴埋めされた文章のリストと、置き換えられたトークンのスコアのリスト。\n","    \"\"\"\n","    # 文章を符号化する。(テンソル化)\n","    input_ids = tokenizer.encode(text, return_tensors='pt')\n","    # GPUに配置する。\n","    input_ids = input_ids.cuda()\n","    with torch.no_grad():\n","        # BERTモデルに入力する。\n","        output = bert_mlm(input_ids=input_ids)\n","    # 分類スコアを取得する。(32,000の各トークンIDに対するスコアの1次配列)\n","    scores = output.logits\n","\n","    # [MASK]の位置を調べる。\n","    mask_position = input_ids[0].tolist().index(4) \n","    # もっともスコアの高いIDを取り出す。(もともと登録されている日本語の語彙は、32,000種類))\n","    topk = scores[0, mask_position].topk(num_topk)\n","    # トークンのID\n","    ids_topk = topk.indices \n","    # IDからトークンの値を取得する。\n","    tokens_topk = tokenizer.convert_ids_to_tokens(ids_topk) \n","    # トークンのスコアを取得する。\n","    scores_topk = topk.values.cpu().numpy() \n","\n","    # 穴埋めされたテキストを格納するための配列\n","    text_topk = [] \n","    # 文章中の[MASK]を上で求めたトークンで置き換える。(num_topk回繰り返す。)\n","    for token in tokens_topk:\n","        # 「##」を空文字に置き換える。\n","        token = token.replace('##', '')\n","        # [MASK]文字を取り替える。\n","        text_topk.append(text.replace('[MASK]', token, 1))\n","\n","    return text_topk, scores_topk\n","\n","# 対象の文章\n","text = '今日は[MASK]へ行く。'\n","# 関数を呼び出す。\n","text_topk, _ = predict_mask_topk(text, tokenizer, bert_mlm, 10)\n","# 結果を出力する。　\n","print(*text_topk, sep='\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yCaGV_rT3A5N"},"source":["# 複数の[MASK]を穴埋めする場合の関数\n","def greedy_prediction(text, tokenizer, bert_mlm):\n","    \"\"\"\n","    [MASK]を含む文章を入力として、貪欲法で穴埋めを行った文章を出力する。\n","    \"\"\"\n","    # 前から順に[MASK]を一つづつ、スコアの最も高いトークンに置き換える。\n","    # この場合は、１つ目の[MASK]を穴埋めした文章に対してさらにもう一度同じ関数を呼び出す。\n","    for _ in range(text.count('[MASK]')):\n","        # predict_mask_topk関数を呼び出す。\n","        text = predict_mask_topk(text, tokenizer, bert_mlm, 1)[0][0]\n","    return text\n","\n","# 対象の文章\n","text = '今日は[MASK][MASK]へ行く。'\n","# 関数の呼び出し\n","greedy_prediction(text, tokenizer, bert_mlm)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"prdEvsxBrrGq"},"source":["# 大部分の文章が[MASK]の場合\n","text = '今日は[MASK][MASK][MASK][MASK][MASK]'\n","# 関数を呼び出す。\n","greedy_prediction(text, tokenizer, bert_mlm)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yHRemOdN0QE9"},"source":["# ビームサーチ法による文章の穴埋めを実行する関数\n","def beam_search(text, tokenizer, bert_mlm, num_topk):\n","    \"\"\"\n","    ビームサーチで文章の穴埋めを行う。\n","    \"\"\"\n","    num_mask = text.count('[MASK]')\n","    # 対象文章を配列に格納する。\n","    text_topk = [text]\n","    # スコアを格納する配列\n","    scores_topk = np.array([0])\n","    # [MASK]の数だけ繰り返す。\n","    for _ in range(num_mask):\n","        # 現在得られている、それぞれの文章に対して、\n","        # 最初の[MASK]をスコアが上位のトークンで穴埋めする。\n","        # それぞれの文章を穴埋めした結果を格納する配列\n","        text_candidates = [] \n","        # 穴埋めに使ったトークンのスコアを格納する配列。\n","        score_candidates = []\n","        for text_mask, score in zip(text_topk, scores_topk):\n","            # predict_mask_topk関数の呼び出し\n","            text_topk_inner, scores_topk_inner = predict_mask_topk(\n","                text_mask, tokenizer, bert_mlm, num_topk\n","            )\n","            # 配列に格納する。\n","            text_candidates.extend(text_topk_inner)\n","            score_candidates.append( score + scores_topk_inner )\n","\n","        # 穴埋めにより生成された文章の中から合計スコアの高いものを選ぶ。\n","        score_candidates = np.hstack(score_candidates)\n","        idx_list = score_candidates.argsort()[::-1][:num_topk]\n","        text_topk = [ text_candidates[idx] for idx in idx_list ]\n","        scores_topk = score_candidates[idx_list]\n","\n","    return text_topk\n","\n","# 対象文章\n","text = \"今日は[MASK][MASK]へ行く。\"\n","# beam_search関数の呼び出し\n","text_topk = beam_search(text, tokenizer, bert_mlm, 10)\n","print(*text_topk, sep='\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5mhL-VSTvUo7"},"source":["# 対象文章\n","text = '今日は[MASK][MASK][MASK][MASK][MASK]'\n","# beam_search関数の呼び出し\n","text_topk = beam_search(text, tokenizer, bert_mlm, 10)\n","print(*text_topk, sep='\\n')"],"execution_count":null,"outputs":[]}]}